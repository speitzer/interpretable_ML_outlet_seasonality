{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "255b4fe3",
   "metadata": {},
   "source": [
    "# Extract Long-Term & Seasonal Components from Time Series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b7cf71",
   "metadata": {},
   "source": [
    "This script separates out the long-term and seasonal components from a time series using a Singular Spectrum Analysis (SSA). If done post-iterpolation via ALPS (recommended), input data is provided as a .csv file without headers with three columns of data: decimal year, interpolated data, date in YYYYMMDD format.\n",
    "\n",
    "Source: Elsner, J. B. and Tsonis, A. A.: Singular spectrum analysis: a new tool in time series analysis, Springer Science & Business Media, 2013."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e0b6d06-b991-46f0-94f0-d8a920930488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# depencencies\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyts.decomposition import SingularSpectrumAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab875bf5-1aab-4140-93db-70ac547c8cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# source directories\n",
    "\n",
    "input_directory = \"/Users/.../interpolated/\"\n",
    "output_directory = \"/Users/.../SSA/\"\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "files = sorted([f for f in os.listdir(input_directory) if f.endswith(\"slope_interpolated.csv\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc76ea1-6454-44ad-a88e-bd9ed0953685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "\n",
    "def my_fft(signal, delta_t, n):\n",
    "    freqs = np.fft.fftfreq(n, d=delta_t)\n",
    "    fft_vals = np.fft.fft(signal)\n",
    "    return freqs[:n // 2], fft_vals[:n // 2]\n",
    "\n",
    "def classify_by_frequency(X_ssa, freq_threshold=0.05, max_seasonal_components=10, amplitude_ratio_threshold=0.1):\n",
    "    longterm_indices = []\n",
    "    seasonal_indices = []\n",
    "\n",
    "    # Compute the amplitude (range) of each component\n",
    "    amplitudes = [X_ssa[i, :].max() - X_ssa[i, :].min() for i in range(X_ssa.shape[0])]\n",
    "    max_amplitude = amplitudes[0]  # Assume the first component is long-term and has the largest amplitude\n",
    "\n",
    "    for i in range(X_ssa.shape[0]):\n",
    "        xf, yf = my_fft(X_ssa[i, :], 1 / 365, len(X_ssa[i, :]))\n",
    "        max_freq = xf[np.argmax(2.0 / len(X_ssa[i, :]) * np.abs(yf))]\n",
    "        relative_amplitude = amplitudes[i] / max_amplitude  # Relative amplitude compared to component 0\n",
    "\n",
    "        if np.abs(max_freq) < freq_threshold:\n",
    "            # Classify as long-term if frequency is very low\n",
    "            longterm_indices.append(i)\n",
    "        elif (np.abs(max_freq - 1) < 0.2 or np.abs(max_freq - 2) < 0.2) and relative_amplitude > amplitude_ratio_threshold:\n",
    "            # Classify as seasonal if frequency is close to 1 or 2 and relative amplitude is significant\n",
    "            seasonal_indices.append(i)\n",
    "\n",
    "    # Limit seasonal indices to the top `max_seasonal_components` based on their order\n",
    "    seasonal_indices = seasonal_indices[:max_seasonal_components]\n",
    "\n",
    "    # Ensure some seasonal indices are defined if none exist\n",
    "    if not seasonal_indices:\n",
    "        max_longterm_index = max(longterm_indices) if longterm_indices else -1\n",
    "        seasonal_indices = [i for i in range(max_longterm_index + 1, 11)]\n",
    "\n",
    "    return longterm_indices, seasonal_indices\n",
    "\n",
    "def extract_components(pd_series, X_ssa, indices):\n",
    "    component = pd.Series(np.sum(X_ssa[indices, :], axis=0), index=pd_series.index)\n",
    "    return component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addcf140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over each file, one per glacierid\n",
    "for file_name in files:\n",
    "    # Extract glacier ID from file name\n",
    "    glacierid = file_name.split(\"_\")[0]\n",
    "    \n",
    "    # Define input and output file paths\n",
    "    input_file_path = os.path.join(input_directory, file_name)\n",
    "    output_file_path = os.path.join(output_directory, f\"{glacierid}_variable_SSA.csv\")\n",
    "    \n",
    "    # Load data\n",
    "    data = np.loadtxt(input_file_path, delimiter=',')\n",
    "    date = pd.to_datetime(data[:, 2], format='%Y%m%d', errors='ignore')\n",
    "    datetime_index = pd.DatetimeIndex(date)\n",
    "    pd_series = pd.Series(data[:, 1], index=datetime_index).sort_index()\n",
    "    pd_series = pd_series[~pd_series.index.duplicated()]\n",
    "    print('Working on glacier: ' + glacierid)\n",
    "    \n",
    "    # Filter data to only include chosen date range\n",
    "    start_date = \"2000-01-01\"\n",
    "    end_date = \"2020-05-01\"\n",
    "    filtered_pd_series = pd_series[start_date:end_date]\n",
    "\n",
    "    # Resample and interpolate to daily frequency for missing dates (leap days etc)\n",
    "    daily_pd_series = filtered_pd_series.resample('1D').interpolate(method='linear')\n",
    "\n",
    "    # Perform SSA\n",
    "    window_size = 365  # One year\n",
    "    ssa = SingularSpectrumAnalysis(window_size=window_size)\n",
    "    X_ssa = ssa.fit_transform(daily_pd_series.values.T[np.newaxis, :])\n",
    "\n",
    "    # Classify components\n",
    "    longterm_indices, seasonal_indices = classify_by_frequency(X_ssa)\n",
    "\n",
    "    # Extract long-term and seasonal components\n",
    "    longterm = extract_components(daily_pd_series, X_ssa, longterm_indices)\n",
    "    seasonal = extract_components(daily_pd_series, X_ssa, seasonal_indices)\n",
    "\n",
    "    # Save data (limited to the filtered date range)\n",
    "    data_save = np.array((\n",
    "        daily_pd_series.index.to_julian_date(),  # Decimal Date (adjusted to daily index within range)\n",
    "        daily_pd_series.values,  # Interpolated values (filtered range)\n",
    "        daily_pd_series.index.strftime('%Y%m%d').astype(int),  # Integer Date\n",
    "        longterm.values,  # Long-term Component (filtered range)\n",
    "        seasonal.values   # Seasonal Component (filtered range)\n",
    "    ))\n",
    "\n",
    "    # Transpose the array to match the expected format\n",
    "    data_save = data_save.T\n",
    "\n",
    "    # Save to the output file\n",
    "    np.savetxt(output_file_path, data_save, delimiter=\",\", header=\"DecimalDate,Value,IntegerDate,LongTerm,Seasonal\", comments=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10dffd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc91747",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ce1fb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
