{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting ALPS through GCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpolates data to daily values. Adapted from source below. Needs the accompanying Functions.py file to run. The code, as written, expects the input data as .csv files beginning with a 3-digit Glacier Identification code (glacierid). Default code assumes the data is saved with a column 'Date' in datetime format and a 'Mean Variable' column with the data you wish to interpolate.\n",
    "\n",
    "Interpolated data is saved as a .csv file without headers with three columns of data: decimal year, interpolated data, date in YYYYMMDD format.\n",
    "\n",
    "Source: \n",
    "Shekhar, P., Csatho, B., Schenk, T., Roberts, C., and Patra, A. K.: Alps: a unified framework for modeling time series of land ice changes, IEEE Transactions on Geoscience and Remote Sensing, 59, 6466â€“6481, 2020.\n",
    "\n",
    "Access: https://github.com/pshekhar-tufts/ALPS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from Functions import *\n",
    "from matplotlib.pyplot import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime as dt\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "from datetime import date\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toYearFraction(date):\n",
    "    def sinceEpoch(date): # returns seconds since epoch\n",
    "        return time.mktime(date.timetuple())\n",
    "    s = sinceEpoch\n",
    "\n",
    "    year = date.year\n",
    "    startOfThisYear = dt(year=year, month=1, day=1)\n",
    "    startOfNextYear = dt(year=year+1, month=1, day=1)\n",
    "\n",
    "    yearElapsed = s(date) - s(startOfThisYear)\n",
    "    yearDuration = s(startOfNextYear) - s(startOfThisYear)\n",
    "    fraction = yearElapsed/yearDuration\n",
    "\n",
    "    return date.year + fraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved interpolated data for glacier 243 to /Users/kevin/Documents/ML_longterm/variables_data/geometric/time_series/interpolated/243_slope_interpolated.csv\n",
      "Processing glacier 246...\n",
      "Saved interpolated data for glacier 246 to /Users/kevin/Documents/ML_longterm/variables_data/geometric/time_series/interpolated/246_slope_interpolated.csv\n",
      "Processing glacier 247...\n",
      "Saved interpolated data for glacier 247 to /Users/kevin/Documents/ML_longterm/variables_data/geometric/time_series/interpolated/247_slope_interpolated.csv\n",
      "Processing glacier 248...\n",
      "Saved interpolated data for glacier 248 to /Users/kevin/Documents/ML_longterm/variables_data/geometric/time_series/interpolated/248_slope_interpolated.csv\n",
      "Processing glacier 251...\n",
      "Saved interpolated data for glacier 251 to /Users/kevin/Documents/ML_longterm/variables_data/geometric/time_series/interpolated/251_slope_interpolated.csv\n",
      "Processing glacier 252...\n",
      "Saved interpolated data for glacier 252 to /Users/kevin/Documents/ML_longterm/variables_data/geometric/time_series/interpolated/252_slope_interpolated.csv\n",
      "Processing glacier 253...\n",
      "Saved interpolated data for glacier 253 to /Users/kevin/Documents/ML_longterm/variables_data/geometric/time_series/interpolated/253_slope_interpolated.csv\n",
      "Processing glacier 255...\n",
      "Saved interpolated data for glacier 255 to /Users/kevin/Documents/ML_longterm/variables_data/geometric/time_series/interpolated/255_slope_interpolated.csv\n",
      "Processing glacier 273...\n",
      "Saved interpolated data for glacier 273 to /Users/kevin/Documents/ML_longterm/variables_data/geometric/time_series/interpolated/273_slope_interpolated.csv\n",
      "Processing glacier 275...\n",
      "Saved interpolated data for glacier 275 to /Users/kevin/Documents/ML_longterm/variables_data/geometric/time_series/interpolated/275_slope_interpolated.csv\n",
      "Processing glacier 278...\n",
      "Saved interpolated data for glacier 278 to /Users/kevin/Documents/ML_longterm/variables_data/geometric/time_series/interpolated/278_slope_interpolated.csv\n",
      "Processing glacier 279...\n",
      "Saved interpolated data for glacier 279 to /Users/kevin/Documents/ML_longterm/variables_data/geometric/time_series/interpolated/279_slope_interpolated.csv\n",
      "Processing glacier 280...\n",
      "Saved interpolated data for glacier 280 to /Users/kevin/Documents/ML_longterm/variables_data/geometric/time_series/interpolated/280_slope_interpolated.csv\n",
      "Processing glacier 281...\n",
      "Saved interpolated data for glacier 281 to /Users/kevin/Documents/ML_longterm/variables_data/geometric/time_series/interpolated/281_slope_interpolated.csv\n",
      "Processing glacier 282...\n",
      "Saved interpolated data for glacier 282 to /Users/kevin/Documents/ML_longterm/variables_data/geometric/time_series/interpolated/282_slope_interpolated.csv\n",
      "Processing glacier 283...\n",
      "Saved interpolated data for glacier 283 to /Users/kevin/Documents/ML_longterm/variables_data/geometric/time_series/interpolated/283_slope_interpolated.csv\n",
      "Processing glacier 284...\n",
      "Saved interpolated data for glacier 284 to /Users/kevin/Documents/ML_longterm/variables_data/geometric/time_series/interpolated/284_slope_interpolated.csv\n",
      "Processing glacier 285...\n",
      "Saved interpolated data for glacier 285 to /Users/kevin/Documents/ML_longterm/variables_data/geometric/time_series/interpolated/285_slope_interpolated.csv\n",
      "Processing glacier 286...\n",
      "Saved interpolated data for glacier 286 to /Users/kevin/Documents/ML_longterm/variables_data/geometric/time_series/interpolated/286_slope_interpolated.csv\n",
      "Processing glacier 288...\n",
      "Saved interpolated data for glacier 288 to /Users/kevin/Documents/ML_longterm/variables_data/geometric/time_series/interpolated/288_slope_interpolated.csv\n",
      "Processing glacier 290...\n",
      "Saved interpolated data for glacier 290 to /Users/kevin/Documents/ML_longterm/variables_data/geometric/time_series/interpolated/290_slope_interpolated.csv\n",
      "Processing glacier 291...\n",
      "Saved interpolated data for glacier 291 to /Users/kevin/Documents/ML_longterm/variables_data/geometric/time_series/interpolated/291_slope_interpolated.csv\n"
     ]
    }
   ],
   "source": [
    "# set a glacierid threshold. this should be 0 unless you need to rerun the code starting after a certain input line number.\n",
    "threshold = 0\n",
    "\n",
    "# Define the directory path. Edit as needed to your path.\n",
    "in_dir  = '/Users/.../original/'\n",
    "out_dir = '/.../interpolated/'\n",
    "\n",
    "# Get all filenames in the directory and sort them by the first three digits (glacierid)\n",
    "csv_files = [filename for filename in os.listdir(in_dir)] \n",
    "csv_files.sort(key=lambda x: int(x[:3]))  # Sort by the first three digits (glacierid)\n",
    "\n",
    "filtered_files = [filename for filename in csv_files if int(filename[:3]) > threshold]\n",
    "\n",
    "# Loop through the sorted list of files\n",
    "for filename in filtered_files:\n",
    "    if filename.endswith('.csv'):\n",
    "        glacierid = filename[:3]  # Get the first three digits as 'glacierid'\n",
    "        print(f\"Processing glacier {glacierid}...\")\n",
    "\n",
    "        # Load the data for glacierid glacier\n",
    "        data = pd.read_csv(os.path.join(in_dir, filename))\n",
    "        data['Date'] = pd.to_datetime(data['Date'])\n",
    "        data = data.dropna(subset=['Mean Variable']).reset_index(drop=True)\n",
    "        # find the mean monthly value if needed - ALPS crashes with too many data points\n",
    "        data = data.groupby(pd.PeriodIndex(data['Date'], freq=\"M\"))['Mean Variable'].mean().reset_index()\n",
    "        data['Date'] = data['Date'].astype(str)\n",
    "        data['Date'] = pd.to_datetime(data['Date'])  # Confirm datetime format\n",
    "        data_arrays = data[['Date', 'Mean Variable']].to_numpy()\n",
    "\n",
    "        # setup data for processing, create decimal date column 'Dec_Date'\n",
    "        decdate = [] \n",
    "        for i in range(len(data_arrays)):\n",
    "            new = data_arrays[i, 0]  \n",
    "            new = toYearFraction(new)  \n",
    "            decdate.append(new) \n",
    "        data['Dec_Date'] = decdate\n",
    "        data_arrays = data[['Dec_Date', 'Mean Variable']].to_numpy()\n",
    "\n",
    "        # Calculate the number of days between first and last dates\n",
    "        d0 = data['Date'].iloc[0]\n",
    "        d1 = data['Date'].iloc[-1]\n",
    "        delta = d1 - d0\n",
    "        num = delta.days + 1\n",
    "\n",
    "        # setup interpolation. See source paper for discussion on changing values of p and q\n",
    "        p = 4\n",
    "        q = 1\n",
    "        [n, lamb, sigmasq] = full_search_nk(data_arrays, p, q)\n",
    "        c = n + p\n",
    "        U = Kno_pspline_opt(data_arrays, p, n)\n",
    "        B = Basis_Pspline(n, p, U, data_arrays[:, 0])\n",
    "        P = Penalty_p(q, c)\n",
    "        theta = np.linalg.solve(B.T.dot(B) + lamb * P, B.T.dot(data_arrays[:, 1].reshape(-1, 1)))\n",
    "\n",
    "        # Getting the mean of the prediction\n",
    "        xpred = np.linspace(data_arrays[0, 0], data_arrays[-1, 0], num)\n",
    "        Bpred = Basis_Pspline(n, p, U, xpred)\n",
    "        ypred1 = Bpred.dot(theta)\n",
    "        std_t1, std_n1 = Var_bounds(data_arrays, Bpred, B, theta, P, lamb)\n",
    "\n",
    "        # Save the interpolated data as an array, adding an integer date column\n",
    "        ypred1 = np.squeeze(ypred1)\n",
    "        sdate = data['Date'].iloc[0]\n",
    "        last = data['Date'].iloc[-1]\n",
    "        edate = last + timedelta(days=1)\n",
    "        dates = pd.date_range(sdate, edate - timedelta(days=1), freq='d')\n",
    "        datesint = [0] * len(dates)\n",
    "        for i in range(len(dates)):\n",
    "            datesint[i] = int(dates[i].strftime('%Y%m%d'))\n",
    "        ALPS_array = np.array((xpred, ypred1, datesint)).T \n",
    "\n",
    "        # Save the results with the glacierid in the filename\n",
    "        output_filename = os.path.join(out_dir, f\"{glacierid}_variable.csv\")\n",
    "        np.savetxt(output_filename, ALPS_array, delimiter=\",\")  # Save as a .csv\n",
    "        print(f\"Saved interpolated data for glacier {glacierid} to {output_filename}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
